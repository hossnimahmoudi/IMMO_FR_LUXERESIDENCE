#!/usr/bin/env python
# -*- coding: utf-8 -*-
from __future__ import unicode_literals

UTF8_ENCODING = 'utf-8'

import sys
reload(sys)
sys.setdefaultencoding(UTF8_ENCODING)

import scrapy
import neukolln.spiders
from neukolln.items import ImmoItem

import logging
logger = logging.getLogger()


class $classname(neukolln.spiders.NeukollnBaseSpider, scrapy.Spider):
    name = '$name'
    allowed_domains = ['google.com']  # FIXME
    start_urls = ['http://www.google.com/']  # FIXME

    def __init__(self, *args, **kwargs):
        super($classname, self).__init__(*args, **kwargs)
        # ...

    def response_is_ban(self, request, response):
        # use default rules, but also consider HTTP 200 responses
        # a ban if there is 'captcha' word in response body.
        ban = super($classname, self).response_is_ban(request, response)
        # ban = ban or 'captcha' in response.body.lower()
        return ban

#    def start_requests(self):
#        """Generate requests here"""
#        # override start_urls!!!

    def parse(self, response):
        pass

