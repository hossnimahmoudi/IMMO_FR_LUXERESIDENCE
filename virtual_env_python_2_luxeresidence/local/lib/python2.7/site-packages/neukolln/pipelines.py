#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html

from __future__ import unicode_literals

import os
import time
import csv
from collections import defaultdict

import codecs
from scrapy import signals
from scrapy.exporters import JsonItemExporter, CsvItemExporter
from scrapy.utils.project import get_project_settings

from neukolln.utils import parse_phone, get_mandatory_variable_from_settings

import sshtunnel
import pymysql
import re

import logging
logger = logging.getLogger()

# value by default in scrapy
# https://doc.scrapy.org/en/latest/topics/exporters.html#scrapy.exporters.CsvItemExporter
SCRAPY_DEFAULT_CSV_ITEM_EXPORTER_JOIN_MULTIVALUED = ','

# SETTINGS
NEUKOLLN_DEFAULT_CC_PREFIX = 'NEUKOLLN_DEFAULT_CC_'  # "CC" for CODE COUNTRY
NEUKOLLN_ORIGINAL_PHONE_PREFIX = 'NEUKOLLN_ORIGINAL_PHONE_'

MAX_CONNEXION_ATTEMPTS = 10
RETRY_DELAY = 3
BULK_INSERT_CHUNKSIZE = 100


class QuoteAllDialect(csv.excel):
    quoting = csv.QUOTE_ALL


class QuoteAllCsvItemExporter(CsvItemExporter):
    def __init__(self, *args, **kwargs):
        kwargs.update({'dialect': QuoteAllDialect})
        super(QuoteAllCsvItemExporter, self).__init__(*args, **kwargs)


class HeadlessCsvItemExporter(QuoteAllCsvItemExporter):
    """Custom Exporter for .TAB output file"""

    def __init__(self, *args, **kwargs):
        if args[0].tell() > 0:
            # args[0] is (opened) file handler
            # if file is not empty then skip headers
            kwargs['include_headers_line'] = False
        super(HeadlessCsvItemExporter, self).__init__(*args, **kwargs)


class SSH_SQL_Pipeline(object):
    """Custom Pipeline to export data into a given database through SSH"""

    def __init__(self):
        """Pipeline to feed db"""
        self.tunnel = None
        self.connection = None
        self.cursor = None
        self.sql_table_name = None
        self.bulk_insert_items = []
        self.fields = sorted(get_mandatory_variable_from_settings('FEED_EXPORT_FIELDS'))

        # Build query
        self.placeholders = ', '.join(["'%s'"] * len(self.fields))
        self.columns = ', '.join(["`" + str(el) + "`" for el in self.fields])

        # Check environment required variables are defined
        for key in ['DB_SSH_HOST',
                    'DB_SSH_PORT',
                    'DB_SSH_USERNAME',
                    #'DB_SSH_PASSWORD',
                    'DB_USERNAME',
                    'DB_PASSWORD',
                    'DB_DATABASE',
                    'DB_CHARSET']:
            try:
                os.environ[key]
                if not 'DB_SSH_PASSWORD' in os.environ and not 'DB_SSH_PKEY' in os.environ:
                    logger.error("[__INIT__][SSH_SQL_PIPELINE][NEUKOLLN] SSH connection needs a password or a public key. ")
            except Exception, e:
                logger.error("[__INIT__][SSH_SQL_PIPELINE][NEUKOLLN] Environment variable is not defined. "
                             "Catched exception: %s" % str(e))
                raise e

    def execute_query(self, query):
        try:
            # Execute and commit query
            n = self.cursor.execute(query)  # n: concerned rows
            self.connection.commit()

            # do stuff with results
            return self.cursor.fetchall() or True

        except pymysql.err.ProgrammingError, e:
            logger.error("[EXECUTE_QUERY][SSH_SQL_PIPELINE][NEUKOLLN] Connection is closed. "
                         "Try again. Re-create. Catched exception: %s" % str(e))
        except Exception, e:
            logger.error("[EXECUTE_QUERY][SSH_SQL_PIPELINE][NEUKOLLN] "
                         "Catched exception: %s, query: %s" % (str(e), query))

    def build_query(self):
        logger.info("[BULK_INSERT_EXECUTE_QUERY][SSH_SQL_PIPELINE][NEUKOLLN] "
                     "Going to send %d items" % len(self.bulk_insert_items))

        query = "INSERT INTO %s (%s) VALUES " % (self.sql_table_name, self.columns)
        for item in self.bulk_insert_items:
            # Cleaning
            for k in self.fields:
                if item.get(k) is None:
                    item[k] = 'NULL'
                else:
                    # FIXME really bad...
                    item[k] = str(item[k]).replace('\n', ' ').replace('\r', ' ').replace('\t', ' ').replace('\\',
                                                                                                            ' ').replace(
                        '"', ' ').replace("'", ' ')
                    item[k] = ' '.join(item[k].split())

            keys = ",".join(map(lambda x: "'{" + x + "}'", self.fields))
            query += "(%s)," % (keys)
            query = query.format(**dict(item))

        query = query[:-1]  # remove comma
        query += ";"  # add semilicon

        logger.debug('[BULK_INSERT_EXECUTE_QUERY][SSH_SQL_PIPELINE][NEUKOLLN] Build query: %s' % query)
        return query

    def bulk_insert(self, spider):
        query = self.build_query()

        # Open connection
        self.open_connection()

        # Execute query
        result = self.execute_query(query)

        # Try several times if error happened
        for i in range(MAX_CONNEXION_ATTEMPTS):
            if result is None:
                self.close_connection()
                self.open_connection()
                result = self.execute_query(query)
            else:
                break

        logger.info("[BULK_INSERT][SSH_SQL_PIPELINE][NEUKOLLN] Query execution returned:  %s" % str(result))
        if not result:
            logger.error("[BULK_INSERT][SSH_SQL_PIPELINE][NEUKOLLN] The following query has not been executed: %s" % query)
        else:
            # RESET
            self.bulk_insert_items = []

        # Close connection
        self.close_connection()

    def process_item(self, item, spider):
        """Process item"""

        # Add item to list
        self.bulk_insert_items.append(item)

        # Insert if BULK_INSERT_CHUNKSIZE has been reached
        if len(self.bulk_insert_items) >= BULK_INSERT_CHUNKSIZE:
            self.bulk_insert(spider)

        # Always return item
        return item

    def close_spider(self, spider):
        # Before closing, insert last items
        if len(self.bulk_insert_items):
            self.bulk_insert(spider)

        # Close connection
        self.close_connection()

    def open_spider(self, spider):
        # The command-line value override the default value
        if hasattr(spider, 'SQL_TABLE_NAME'):
            self.sql_table_name = spider.SQL_TABLE_NAME
        else: 
            self.sql_table_name = get_project_settings().get('TABLE_NAME')

    def open_connection(self):
        """Utils method. Connect to db"""

        logger.debug("[OPEN_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] Opening tunnel...")

        ###
        # Instantiate/create SSH tunnel
        ###
        retries = MAX_CONNEXION_ATTEMPTS
        while not self.tunnel and retries:
            # try to open SSH tunnel
            # several attempts can be needed...
            try: 
                try:
                    password = os.environ['DB_SSH_PASSWORD']
                except Exception as e:
                    password = None

                try:
                    pkey = os.environ['DB_SSH_PKEY']
                except Exception as e:
                    pkey = None

                if not password and not pkey:
                    # Should be already catched before, just in case
                    logger.error("[OPEN_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] SSH connection needs a password or a public key. ")

                self.tunnel = sshtunnel.SSHTunnelForwarder(
                    ssh_address_or_host=(os.environ['DB_SSH_HOST'], int(os.environ['DB_SSH_PORT'])),
                    remote_bind_address=(os.getenv('DB_SSH_SQL_HOST', '127.0.0.1'), 3306),
                    ssh_username=os.environ['DB_SSH_USERNAME'],
                    ssh_password=password,
                    ssh_pkey=pkey)

            except Exception, e:
                retries -= 1
                logger.error("[OPEN_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] Fail to open tunnel for %d time(s). "
                             "Retrying...(wait %s seconds before reconnect) "
                             "Catched exception: %s" % ((MAX_CONNEXION_ATTEMPTS - retries),
                                                        RETRY_DELAY,
                                                        str(e)))
                time.sleep(RETRY_DELAY)

                if not retries:
                    # fail to connect!!!
                    raise e

        ###
        # Instantiate/create SQL connection and cursor
        ###

        # Use while loop to avoid following error
        #   "sshtunnel.BaseSSHTunnelForwarderError: Could not establish session to SSH gateway"
        retries = MAX_CONNEXION_ATTEMPTS
        while not self.tunnel.tunnel_is_up and not self.tunnel.is_active:
            try:
                self.tunnel.start()  # start tunnel
                time.sleep(RETRY_DELAY)
            except Exception, e:
                retries -= 1
                logger.error("[OPEN_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] Fail to awake tunnel for %d time(s). "
                             "Retrying...(wait %s seconds before reconnect) "
                             "Catched exception: %s" % ((MAX_CONNEXION_ATTEMPTS - retries),
                                                        RETRY_DELAY,
                                                        str(e)))
                time.sleep(RETRY_DELAY)

                if not retries:
                    # fail to connect!!!
                    raise e

        logger.debug("[OPEN_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] Tunnel is open. Done.")
        logger.debug("[OPEN_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] Opening SQL connection...")

        # open connection
        retries = MAX_CONNEXION_ATTEMPTS
        while not self.connection and retries:
            # try to create SQL connection
            # while loop really needed?
            try:
                self.connection = pymysql.connect(host='127.0.0.1',
                                                 user=os.environ['DB_USERNAME'],
                                                 database=os.environ['DB_DATABASE'],
                                                 password=os.environ['DB_PASSWORD'],
                                                 charset=os.environ['DB_CHARSET'],
                                                 port=self.tunnel.local_bind_port)
            except Exception, e:
                retries -= 1
                logger.error("[OPEN_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] Fail to open connection for %d time(s). "
                             "Retrying...(wait %s seconds before reconnect) "
                             "Catched exception: %s" % ((MAX_CONNEXION_ATTEMPTS - retries),
                                                        RETRY_DELAY,
                                                        str(e)))
                time.sleep(RETRY_DELAY)

                if not retries:
                    # fail to connect!!!
                    raise e

        logger.debug("[OPEN_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] Connection is open. Done.")

        ###
        # Instantiate/create cursor
        ###
        self.cursor = self.connection.cursor()

    def close_connection(self):
        """Utils method. Force/close connection"""
        try:
            self.cursor.close()  # close cursor!!!
            self.cursor = None
            logger.debug("[CLOSE_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] Cursor is closed")
        except Exception, e:
            logger.error("[CLOSE_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] self.cursor: %s" % str(e))
        try:
            self.connection.close()  # close connection!!!
            self.connection = None
            logger.debug("[CLOSE_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] Connection is closed")
        except Exception, e:
            logger.error("[CLOSE_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] self.connection: %s" % str(e))
        try:
            self.tunnel.close()  # close tunnel!!!
            self.tunnel = None
            logger.debug("[CLOSE_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] Tunnel is closed")
        except Exception, e:
            logger.error("[CLOSE_CONNECTION][SSH_SQL_PIPELINE][NEUKOLLN] self.tunnel: %s" % str(e))


class CSV_JSON_TAB_Pipeline(object):
    """Custom Pipeline to export data as JSON, CSV abd TAB output files"""

    def __init__(self):
        # Output files
        self.files = defaultdict(list)
        self.exporters = []

        # Main configuration variables from settings.py

        # Non-mandatory
        self.settings = get_project_settings()
        self.FEED_EXPORT_DELIMITER = self.settings.get('FEED_EXPORT_DELIMITER', b';')
        self.FEED_EXPORT_ENCODING = self.settings.get('FEED_EXPORT_ENCODING', 'utf-8')
        self.NEUKOLLN_OUTPUTS_FOLDER = self.settings.get('NEUKOLLN_OUTPUTS_FOLDER', "outputs")

        assert self.FEED_EXPORT_DELIMITER != SCRAPY_DEFAULT_CSV_ITEM_EXPORTER_JOIN_MULTIVALUED, \
            'CSV delimiter and join_multivalued CsvItemExporter parameter have to be different!'

        # Mandatory
        self.FEED_EXPORT_FIELDS = get_mandatory_variable_from_settings('FEED_EXPORT_FIELDS')
        self.BOT_NAME = get_mandatory_variable_from_settings('BOT_NAME')

        # Configuration from the spider. JSON is always used as back-up data file
        self.neukolln_export_to_json = True
        self.neukolln_export_to_csv = False
        self.neukolln_export_to_tab = False

        # Configuration from spider
        self.crawl_date = None

    @classmethod
    def from_crawler(cls, crawler):
        pipeline = cls()
        crawler.signals.connect(pipeline.spider_opened, signals.spider_opened)
        crawler.signals.connect(pipeline.spider_closed, signals.spider_closed)
        return pipeline

    def spider_opened(self, spider):

        if hasattr(spider, 'NEUKOLLN_OUTPUTS_FOLDER'):
            self.NEUKOLLN_OUTPUTS_FOLDER = spider.NEUKOLLN_OUTPUTS_FOLDER

        if hasattr(spider, 'date'):
            # Get the value from the spider
            self.crawl_date = spider.date
        else:
            # Set it by default with the date of crawl launch
            today = time.strftime("%Y%m%d")
            self.crawl_date = today

        path = "%s/%s" % (self.NEUKOLLN_OUTPUTS_FOLDER, self.crawl_date)
        now = time.strftime("%Y%m%d_%Hh-%Mmin-%Ss")
        if hasattr(spider, 'EXPORT_FILENAME'):
            filename = "%s_%s" % (spider.EXPORT_FILENAME.lower(), now)
        else:
            filename = "%s_%s" % (self.BOT_NAME.lower(), now)

        # [DEBUG] Inform user
        logger.debug("[OPENED_SPIDER][PIPELINE][NEUKOLLN] Output data files will be stored in %(path)s" % {'path': path})

        if not os.path.exists(path):
            os.makedirs(path)

        file = "{0}/{1}".format(path, filename)
        # useful to access the output of a crawl in the spider by using : self.EXPORT_PATH and self.EXPORT_FILENAME
        setattr(spider, 'EXPORT_PATH', path)
        setattr(spider, 'EXPORT_FILENAME', filename)

        self.neukolln_export_to_json = getattr(spider, 'neukolln_export_to_json', self.neukolln_export_to_json)
        if self.neukolln_export_to_json:
            json_file = codecs.open(file + '.json', 'w+b', encoding=self.FEED_EXPORT_ENCODING)
            self.files[spider].append(json_file)
            self.exporters.append(JsonItemExporter(json_file,
                                                   encoding=self.FEED_EXPORT_ENCODING,
                                                   fields_to_export=self.FEED_EXPORT_FIELDS))

        self.neukolln_export_to_csv = getattr(spider, 'neukolln_export_to_csv', self.neukolln_export_to_csv)
        if self.neukolln_export_to_csv:
            csv_file = codecs.open(file + '.csv', 'w+b', encoding=self.FEED_EXPORT_ENCODING)
            self.files[spider].append(csv_file)
            self.exporters.append(QuoteAllCsvItemExporter(csv_file,
                                                  join_multivalued=SCRAPY_DEFAULT_CSV_ITEM_EXPORTER_JOIN_MULTIVALUED,
                                                  encoding=self.FEED_EXPORT_ENCODING,
                                                  fields_to_export=self.FEED_EXPORT_FIELDS,
                                                  delimiter=self.FEED_EXPORT_DELIMITER))

        self.neukolln_export_to_tab = getattr(spider, 'neukolln_export_to_tab', self.neukolln_export_to_tab)
        if self.neukolln_export_to_tab:
            tab_file = codecs.open(file + '.tab', 'w+b', encoding=self.FEED_EXPORT_ENCODING)
            self.files[spider].append(tab_file)
            self.exporters.append(HeadlessCsvItemExporter(tab_file,
                                                          join_multivalued=SCRAPY_DEFAULT_CSV_ITEM_EXPORTER_JOIN_MULTIVALUED,
                                                          encoding=self.FEED_EXPORT_ENCODING,
                                                          fields_to_export=self.FEED_EXPORT_FIELDS,
                                                          delimiter=b'\t'))

        for exporter in self.exporters:
            exporter.start_exporting()

    def spider_closed(self, spider):
        for exporter in self.exporters:
            exporter.finish_exporting()

        files = self.files.pop(spider)
        for file in files:
            file.close()

    def process_item(self, item, spider):
        """
        This function is called each time we yield an item.
        This is useful to process item data before storing it in json or csv
        """

        # First parse, clean and format all phone numbers
        NEUKOLLN_ORIGINAL_PHONE_DATA = [k for k in self.FEED_EXPORT_FIELDS if (k.find(NEUKOLLN_ORIGINAL_PHONE_PREFIX) != -1)]
        if not len(NEUKOLLN_ORIGINAL_PHONE_DATA):
            # [DEBUG] No original phone data has been given! phonenumber library won't be used!
            logger.debug("[PROCESS_ITEM][PIPELINE][NEUKOLLN] No original phone data has been given. "
                         "The phonenumber library won't be used at all.")
        for key in NEUKOLLN_ORIGINAL_PHONE_DATA:
            # Get all sorted phone keys e.g. (TEL, TEL_2, TEL_3, etc.)
            key = key.replace(NEUKOLLN_ORIGINAL_PHONE_PREFIX, '')
            related_phone_keys = [k for k in sorted(self.FEED_EXPORT_FIELDS)
                                  if ((k.find(key) != -1) and (k.find(NEUKOLLN_ORIGINAL_PHONE_PREFIX) == -1))
                                  and (k.find(NEUKOLLN_DEFAULT_CC_PREFIX) == -1)]
            if related_phone_keys:
                # Get main phone key
                k = related_phone_keys[0]
                # Phone number formatting
                if (not (NEUKOLLN_DEFAULT_CC_PREFIX + k) in item) and ((NEUKOLLN_ORIGINAL_PHONE_PREFIX + k) in item):
                    # [ERROR] Default code country has NOT been set!
                    # The treatment by the phonenumber library won't be possible!
                    logger.error("[PROCESS_ITEM][PIPELINE][NEUKOLLN] Default code country %s is missing in the item. "
                                 "The treatment by the phonenumber library won't be possible as a consequence."
                                 % (NEUKOLLN_DEFAULT_CC_PREFIX + k))
                elif ((NEUKOLLN_DEFAULT_CC_PREFIX + k) in item) and ((NEUKOLLN_ORIGINAL_PHONE_PREFIX + k) in item):
                    # Parse
                    item[k], item[NEUKOLLN_DEFAULT_CC_PREFIX + k] = parse_phone(item.get(NEUKOLLN_ORIGINAL_PHONE_PREFIX + k),
                                                                                item.get(NEUKOLLN_DEFAULT_CC_PREFIX + k))
                # If there are several phones which have been returned by the parsing...
                if item.get(k) and hasattr(item[k], "__iter__") and len(item[k]) > 1:
                    phones = item[k]
                    # For 0 to (min(len(item[k]), len(phone_keys)) -1)
                    for i in range(0, min(len(item[k]), len(related_phone_keys)), 1):
                        if i == len(related_phone_keys) - 1:
                            # put everything in the last case of the array
                            item[related_phone_keys[i]] = phones[i:]
                        else:
                            item[related_phone_keys[i]] = phones[i]

        # Some cleaning because of the delimiters
        for k in self.FEED_EXPORT_FIELDS:
            try:
                # If is array => convert to string
                if hasattr(item[k], "__iter__"):
                    # Remove None or empty values before
                    item[k] = [el for el in item[k] if (el is not None) and (len(el) != 0)]
                    # Cast all values to string
                    item[k] = map(str, item[k])
                    if self.neukolln_export_to_csv:
                        # Replace delimiter by space
                        item[k] = [el.replace(self.FEED_EXPORT_DELIMITER, " ") for el in item[k]]
                    if self.neukolln_export_to_tab or self.neukolln_export_to_csv:
                        # Replace TAB delimiter by space
                        item[k] = [el.replace('\t', ' ').replace('\n', ' ').replace('\r', ' ').replace('\\', '') for el in item[k]]
                    # Clean text: remove multiple spaces
                    item[k] = [' '.join(el.split()) for el in item[k]]
                    # Transform array into a comma separated string
                    item[k] = str([el.encode(self.FEED_EXPORT_ENCODING) for el in item[k]])[1:-1].replace("'", "")
                    # item[k] = SCRAPY_DEFAULT_CSV_ITEM_EXPORTER_JOIN_MULTIVALUED.join(item[k])

                if isinstance(item[k], basestring):
                    if self.neukolln_export_to_csv:
                        # Replace delimiter by space
                        item[k] = item[k].replace(self.FEED_EXPORT_DELIMITER, " ")
                    if self.neukolln_export_to_tab or self.neukolln_export_to_csv:
                        # Replace TAB delimiter by space
                        item[k] = item[k].replace('\t', ' ').replace('\n', ' ').replace('\r', ' ').replace('\\', '')
                    # Clean text: remove multiple spaces
                    item[k] = ' '.join(item[k].split())

                if not item[k]:
                    item[k] = ''
            except KeyError:
                item[k] = ''
            except Exception, e:
                # [ERROR] Alert user
                if hasattr(item[k], "__iter__"):
                    logger.error("[PROCESS_ITEM][PIPELINE][NEUKOLLN] Fail while cleaning item[%s]=[%s]" %
                                 (k, str(item[k])[1:-1]))
                else:
                    logger.error("[PROCESS_ITEM][PIPELINE][NEUKOLLN] Fail while cleaning item[%s]=%s" %
                                 (k, item[k]))
                # raise Exception
                raise e

        for exporter in self.exporters:
            exporter.export_item(item)

        return item
